{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "![](https://blog.keras.io/img/seq2seq/seq2seq-inference.png)\n",
    "\n",
    "> 우리는 문장을 번역하는 모델을 구성해보도록 하겠습니다. **기계번역**이라 불리는 Neural Machine Translate는 파파고, 구글 번역기 등을 떠올리면 됩니다. Neural Machine Traslation에서 가장 기본적인 모델이 되는 Seq2Seq을 구현해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# \\[ 한글 영어 데이터 셋 \\]\n",
    "---\n",
    "---\n",
    "\n",
    "총 50개의 단문 문장 세트를 통해, 번역기를 학습시켜 보도록하겠습니다. 매우 짧은 문장으로만 구성되어 있기 때문에, 번역기다운 번역기는 만들지 못하지만, 학습되는지를 확인해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "너는 나를 사랑한다      >>>  you love me\n",
      "나는 너와 친하다       >>>  I am close to you\n",
      "나는 널 존중해        >>>  I respect you\n",
      "나는 너를 좋아한다      >>>  I like you\n",
      "나는 너가 싫어        >>>  I hate you\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('./short-sentence.txt'):\n",
    "    !wget https://pai-datasets.s3.ap-northeast-2.amazonaws.com/alai-deeplearning/kor.txt\n",
    "df = pd.read_csv(\"./short-sentence.txt\")\n",
    "df = df.sample(frac=1) # 순서를 섞어줌\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "for idx, row in df.iloc[:5].iterrows():\n",
    "    print(f\"{row.Korean:16s}>>>  {row.English}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. 데이터 파악하기\n",
    "---\n",
    "\n",
    "* 문장길이, 철자 수 등을 파악해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 데이터 전처리하기\n",
    "\n",
    "대소문자 구분은 번역에서 핵심은 아니므로, 전부 소문자로 바꾸도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.English = df.English.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 문장 길이 파악하기\n",
    "\n",
    "철자를 기준으로 문장 길이를 세면, 한글이 영어에 비해 짧은 구조를 가지고 있습니다.<br>\n",
    "한글은 기본적으로 초성, 중성, 종성의 구조를 띄고 있기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(df.Korean.map(lambda x : len(x))\n",
    "   .plot(kind='hist', alpha=0.5,\n",
    "         title='The Length of Korean sentence'))\n",
    "(df.English.map(lambda x : len(x))\n",
    "   .plot(kind='hist', alpha=0.5,\n",
    "         title='The Length of English sentence'))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 고유 철자 수 세기\n",
    "\n",
    "현재 문장에서 등장했던 철자들을 파악해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kor_chars = list(set(\" \".join(df.Korean.values))) \n",
    "eng_chars = list(set(\" \".join(df.English.values))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 철자 갯수 : 21\n",
      "한글 철자 갯수 : 35\n"
     ]
    }
   ],
   "source": [
    "print(\"영어 철자 갯수 :\",len(eng_chars))\n",
    "print(\"한글 철자 갯수 :\",len(kor_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 특수 토큰 추가하기 \n",
    "\n",
    "모델에서는 우리가 Padding을 의미하는 토큰과, 문장의 시작 및 끝을 의미하는 EOS 토큰이 필요합니다. 잘 쓰지 않는 특수 기호를 통해, 두 토큰을 추가하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = \"\\t\"\n",
    "EOS = \"\\n\"\n",
    "\n",
    "kor_chars = [PAD] + kor_chars + [EOS] # \\t : <padding> 토큰\n",
    "eng_chars = [PAD] + eng_chars + [EOS] # \\n : <eos> 토큰\n",
    "\n",
    "kor2idx = {char : idx for idx, char in enumerate(kor_chars)}\n",
    "eng2idx = {char : idx for idx, char in enumerate(eng_chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한글 input size : 37\n",
      "영어 input size : 23\n"
     ]
    }
   ],
   "source": [
    "print(\"한글 input size :\",len(kor2idx))\n",
    "print(\"영어 input size :\",len(eng2idx))\n",
    "\n",
    "kor_size = len(kor2idx)\n",
    "eng_size = len(eng2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 리스트의 첫 단어로 \"\\t\"를 추가한 것은, Padding 토큰이 영 벡터를 의미하도록 하기 위합니다.<br>\n",
    "나중에 `pad_sequences` 메소드의 경우, 자동으로 영 벡터를 패딩 토큰으로 삼기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Korean = df.Korean.map(\n",
    "    lambda sent : [kor2idx[char] for char in sent])\n",
    "df.English = df.English.map(\n",
    "    lambda sent : [eng2idx[char] for char in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작과 끝에 <EOS>와 <EOS> 붙임\n",
    "df.English = df.English.map(\n",
    "    lambda x : [eng2idx['\\n']] + x + [eng2idx['\\n']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 6, 15, 28, 26, 15, 10, 7, 11, 5]>>>[22, 8, 17, 21, 9, 4, 17, 10, 12, 9, 11, 12, 22]\n",
      "[28, 6, 15, 32, 23, 15, 30, 20, 5]>>>[22, 3, 9, 13, 11, 9, 18, 4, 17, 16, 12, 9, 19, 17, 9, 8, 17, 21, 22]\n",
      "[28, 6, 15, 1, 15, 13, 34, 22]>>>[22, 3, 9, 1, 12, 16, 14, 12, 18, 19, 9, 8, 17, 21, 22]\n",
      "[28, 6, 15, 32, 26, 15, 21, 25, 11, 5]>>>[22, 3, 9, 4, 3, 6, 12, 9, 8, 17, 21, 22]\n",
      "[28, 6, 15, 32, 18, 15, 27, 31]>>>[22, 3, 9, 5, 13, 19, 12, 9, 8, 17, 21, 22]\n",
      "[32, 6, 15, 28, 26, 15, 2, 4, 22]>>>[22, 8, 17, 21, 9, 5, 13, 19, 12, 9, 11, 12, 22]\n"
     ]
    }
   ],
   "source": [
    "for idx, row in df.loc[:5].iterrows():\n",
    "    print(f\"{row.Korean}>>>{row.English}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) 패딩 추가하기\n",
    "\n",
    "원활한 학습을 위해, 우리는 행렬의 크기를 맞추기 위해, padding을 추가하게 됩니다.<br>\n",
    "Seq2Seq을 위해서는 우리는 크게 3가지의 데이터가 필요합니다. Encoder의 입력값, Decoder의 입력값, Deocder의 출력값으로, 아래와 같이 구성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "encoder_input_data = pad_sequences(df.Korean, padding='post')\n",
    "decoder_input_data = pad_sequences(df.English, padding='post')\n",
    "\n",
    "decoder_output_data = decoder_input_data[:,1:] # 첫 단어 떼기\n",
    "decoder_output_data = pad_sequences(decoder_output_data,\n",
    "                                    maxlen=decoder_input_data.shape[1],\n",
    "                                    padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Seq2Seq 모델 학습시키기\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "Seq2Seq모델을 제안하였던 `Sequence to Sequence Learning with Neural Networks`을 읽으며 구현해보도록 하겠습니다.RNN의 모델 경우, GPU 메모리를 매우 많이 필요로 하기 때문에, 이번 시간에서는 별도로 구현하지 않겠습니다.(논문에서는 8개의 GPU로 10일을 돌렸다고 함)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Seq2Seq의 구조 파악하기\n",
    "\n",
    "----\n",
    "\n",
    "* Seq2Seq 모델은 두 개의 RNN 모델을 나누어, Encoding과 Decoding을 동작시키는 모델입니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Encoder와 Decoder\n",
    "\n",
    "우리는 지난 시간에 배웠던 Auto Encoder의 구조를 떠올려 봅시다. <br>\n",
    "Auto Encoder는 크게 Encoder와 Decoder로 나뉘어 지는데, Encoder는 큰 차원의 입력값을 작은 차원의 latent vector로 압축시키는 구조이고, decoder는 역으로 작은 차원의 latent vector를 큰 차원의 출력값으로 복원시키는 구조입니다.\n",
    "\n",
    "이와 마찬가지로, Seq2Seq 모델도 Encoder에서 입력 순차 데이터에서 Context 정보를 뽑아내고, 이러한 정보에서 원하는 순차 데이터로 출력하는 구조입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Context Vector란\n",
    "\n",
    "Context Vector는 입력 순차 데이터에 대한 RNN 모델의 마지막 State Vector입니다.<br>\n",
    "RNN Model에선 State Vector는 이전에 들어왔던 입력 정보들의 History를 담아낸 정보입니다.\n",
    "\n",
    "그리고 보다 긴 순차 데이터의 정보들을 표현하기 위해서 주로 Vanilla RNN보다는 LSTM 모델을 이용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) <EOS\\> 토큰\n",
    "\n",
    "우리는 Decoder 모델에서 첫번째 출력값과 마지막 출력값을 의미하는 토큰이 필요합니다.<br>\n",
    "그렇지 않으면, Decoder 모델은 언제 출력을 멈춰야 하는지도 모른채, 계속 생성해야 할 수 있기 때문입니다.<br>\n",
    "\n",
    "이러한 목적으로 우리는 보통 <EOS\\>, End-Of-Sequence라 불리는 토큰을 이용합니다. Decoder의 입력이 시작될 때와, 출력이 마무리될 때 위의 토큰을 반환하도록 학습하게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. Encoder-Decoder 구성하기\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Layer 구성하기\n",
    "\n",
    "4층만큼 깊이 하지 않고, 1층으로만 구성하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.initializers import random_uniform\n",
    "\n",
    "class Encoder(Layer):\n",
    "    def __init__(self, input_size, embed_size, state_size, **kwargs):\n",
    "        self.embedding_layer = Embedding(input_size, \n",
    "                                         embed_size, mask_zero=True)\n",
    "        self.lstm_layer = LSTM(state_size, return_state=True)\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        reversed_inputs = K.reverse(inputs,axes=-1)\n",
    "        embeded = self.embedding_layer(reversed_inputs)\n",
    "        _, state_h, state_c = self.lstm_layer(embeded)\n",
    "        return [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Layer):\n",
    "    def __init__(self, output_size, embed_size, state_size, **kwargs):\n",
    "        self.embedding_layer = Embedding(output_size,\n",
    "                                         embed_size, mask_zero=True)\n",
    "        self.lstm_layer = LSTM(state_size,return_sequences=True,\n",
    "                               return_state=True)\n",
    "        self.dense_layer = Dense(output_size,activation='softmax')\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def call(self, inputs, **kwargs):\n",
    "        # inputs를 아래와 같이 \n",
    "        dec_input = inputs[0]\n",
    "        dec_states = inputs[1:]\n",
    "\n",
    "        mode = kwargs.get('mode')\n",
    "\n",
    "        embeded = self.embedding_layer(dec_input)\n",
    "        hidden, state_h, state_c = self.lstm_layer(embeded,\n",
    "                                                   initial_state=dec_states)\n",
    "        output = self.dense_layer(hidden)\n",
    "        \n",
    "        if mode == \"training\":\n",
    "            return output\n",
    "        elif mode == \"inference\":\n",
    "            return [output, state_h, state_c]\n",
    "        else:\n",
    "            raise ValueError(\"mode는 training 혹은 inference에서 정해야 합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 학습용 모델 구성하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0626 15:34:10.898507 4527814080 deprecation.py:323] From /Users/ksj/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py:3794: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "embed_size = 32 # 임베딩 크기\n",
    "state_size = 256 # State 크기\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "# Training 용 Seq2Seq 모델 만들기\n",
    "enc_inputs = Input(shape=(None,))\n",
    "dec_inputs = Input(shape=(None,))\n",
    "\n",
    "encoder = Encoder(kor_size, embed_size, state_size)\n",
    "decoder = Decoder(eng_size, embed_size, state_size)\n",
    "\n",
    "contexts = encoder(enc_inputs)\n",
    "dec_output = decoder([dec_inputs]+contexts,\n",
    "                     mode='training')\n",
    "\n",
    "model = Model(inputs=[enc_inputs, dec_inputs],\n",
    "              outputs=dec_output,\n",
    "              name='training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 추론용 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Model 구성하기\n",
    "encoder_model = Model(enc_inputs,contexts, name='encoder')\n",
    "\n",
    "# Decoder Model 구성하기\n",
    "dec_h_input = Input(shape=(state_size,))\n",
    "dec_c_input = Input(shape=(state_size,))\n",
    "\n",
    "state_inputs = [dec_h_input, dec_c_input]\n",
    "\n",
    "infer_outputs = decoder([dec_inputs]+state_inputs,\n",
    "                        mode='inference')\n",
    "\n",
    "decoder_model = Model([dec_inputs]+state_inputs,\n",
    "                      infer_outputs,\n",
    "                      name='decoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. 모델 학습시키기\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 모델 컴파일하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(1e-3),\n",
    "              loss=sparse_categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 모델 학습시키기\n",
    "\n",
    "200 Epoch 정도로 학습시켜서, Loss가 충분히 떨어진 후 Test 해보도록 하겠습니다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45 samples, validate on 5 samples\n",
      "Epoch 1/200\n",
      "45/45 [==============================] - 2s 43ms/sample - loss: 1.8764 - val_loss: 1.5469\n",
      "Epoch 2/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 1.7991 - val_loss: 1.4006\n",
      "Epoch 3/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 1.6888 - val_loss: 1.3506\n",
      "Epoch 4/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 1.6171 - val_loss: 1.3587\n",
      "Epoch 5/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 1.5827 - val_loss: 1.2922\n",
      "Epoch 6/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 1.5299 - val_loss: 1.3050\n",
      "Epoch 7/200\n",
      "45/45 [==============================] - 1s 13ms/sample - loss: 1.4831 - val_loss: 1.2389\n",
      "Epoch 8/200\n",
      "45/45 [==============================] - 1s 14ms/sample - loss: 1.4585 - val_loss: 1.2645\n",
      "Epoch 9/200\n",
      "45/45 [==============================] - 1s 14ms/sample - loss: 1.4210 - val_loss: 1.1472\n",
      "Epoch 10/200\n",
      "45/45 [==============================] - 1s 14ms/sample - loss: 1.3857 - val_loss: 1.1865\n",
      "Epoch 11/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 1.3503 - val_loss: 1.1404\n",
      "Epoch 12/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 1.3260 - val_loss: 1.1056\n",
      "Epoch 13/200\n",
      "45/45 [==============================] - 1s 15ms/sample - loss: 1.2914 - val_loss: 1.0948\n",
      "Epoch 14/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 1.2391 - val_loss: 1.0091\n",
      "Epoch 15/200\n",
      "45/45 [==============================] - 1s 13ms/sample - loss: 1.1958 - val_loss: 0.9645\n",
      "Epoch 16/200\n",
      "45/45 [==============================] - 1s 15ms/sample - loss: 1.1626 - val_loss: 0.9305\n",
      "Epoch 17/200\n",
      "45/45 [==============================] - 1s 15ms/sample - loss: 1.1001 - val_loss: 0.8688\n",
      "Epoch 18/200\n",
      "45/45 [==============================] - 1s 13ms/sample - loss: 1.0582 - val_loss: 0.8847\n",
      "Epoch 19/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 0.9676 - val_loss: 0.7481\n",
      "Epoch 20/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.9115 - val_loss: 0.7638\n",
      "Epoch 21/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.8404 - val_loss: 0.6467\n",
      "Epoch 22/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.7673 - val_loss: 0.6195\n",
      "Epoch 23/200\n",
      "45/45 [==============================] - 1s 13ms/sample - loss: 0.7008 - val_loss: 0.5951\n",
      "Epoch 24/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.6487 - val_loss: 0.5658\n",
      "Epoch 25/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.5995 - val_loss: 0.5570\n",
      "Epoch 26/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 0.5552 - val_loss: 0.5285\n",
      "Epoch 27/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.5204 - val_loss: 0.5162\n",
      "Epoch 28/200\n",
      "45/45 [==============================] - 1s 13ms/sample - loss: 0.4814 - val_loss: 0.4894\n",
      "Epoch 29/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.4460 - val_loss: 0.4478\n",
      "Epoch 30/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 0.4059 - val_loss: 0.4469\n",
      "Epoch 31/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 0.3779 - val_loss: 0.3997\n",
      "Epoch 32/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 0.3449 - val_loss: 0.3813\n",
      "Epoch 33/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 0.3299 - val_loss: 0.3768\n",
      "Epoch 34/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 0.3234 - val_loss: 0.3296\n",
      "Epoch 35/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 0.3020 - val_loss: 0.3286\n",
      "Epoch 36/200\n",
      "45/45 [==============================] - 1s 13ms/sample - loss: 0.2815 - val_loss: 0.3177\n",
      "Epoch 37/200\n",
      "45/45 [==============================] - 1s 13ms/sample - loss: 0.2642 - val_loss: 0.2824\n",
      "Epoch 38/200\n",
      "45/45 [==============================] - 1s 14ms/sample - loss: 0.2268 - val_loss: 0.2460\n",
      "Epoch 39/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 0.2095 - val_loss: 0.2106\n",
      "Epoch 40/200\n",
      "45/45 [==============================] - 1s 13ms/sample - loss: 0.1929 - val_loss: 0.2045\n",
      "Epoch 41/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 0.1763 - val_loss: 0.1777\n",
      "Epoch 42/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 0.1613 - val_loss: 0.1570\n",
      "Epoch 43/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 0.1495 - val_loss: 0.1584\n",
      "Epoch 44/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 0.1418 - val_loss: 0.1461\n",
      "Epoch 45/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 0.1313 - val_loss: 0.1359\n",
      "Epoch 46/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 0.1209 - val_loss: 0.1331\n",
      "Epoch 47/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 0.1103 - val_loss: 0.1276\n",
      "Epoch 48/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 0.1052 - val_loss: 0.1195\n",
      "Epoch 49/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 0.0989 - val_loss: 0.1151\n",
      "Epoch 50/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 0.0922 - val_loss: 0.1033\n",
      "Epoch 51/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 0.0878 - val_loss: 0.1023\n",
      "Epoch 52/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0818 - val_loss: 0.0900\n",
      "Epoch 53/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0780 - val_loss: 0.0952\n",
      "Epoch 54/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0765 - val_loss: 0.0951\n",
      "Epoch 55/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0749 - val_loss: 0.0913\n",
      "Epoch 56/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0700 - val_loss: 0.0959\n",
      "Epoch 57/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0657 - val_loss: 0.0821\n",
      "Epoch 58/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0634 - val_loss: 0.0828\n",
      "Epoch 59/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0564 - val_loss: 0.0821\n",
      "Epoch 60/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0556 - val_loss: 0.0741\n",
      "Epoch 61/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.0496 - val_loss: 0.0691\n",
      "Epoch 62/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0473 - val_loss: 0.0721\n",
      "Epoch 63/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0469 - val_loss: 0.0630\n",
      "Epoch 64/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0455 - val_loss: 0.0721\n",
      "Epoch 65/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.0451 - val_loss: 0.0785\n",
      "Epoch 66/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0382 - val_loss: 0.0563\n",
      "Epoch 67/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0346 - val_loss: 0.0618\n",
      "Epoch 68/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0326 - val_loss: 0.0598\n",
      "Epoch 69/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0305 - val_loss: 0.0544\n",
      "Epoch 70/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.0298 - val_loss: 0.0585\n",
      "Epoch 71/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.0285 - val_loss: 0.0552\n",
      "Epoch 72/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0248 - val_loss: 0.0587\n",
      "Epoch 73/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.0213 - val_loss: 0.0496\n",
      "Epoch 74/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0201 - val_loss: 0.0494\n",
      "Epoch 75/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0184 - val_loss: 0.0461\n",
      "Epoch 76/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0192 - val_loss: 0.0492\n",
      "Epoch 77/200\n",
      "45/45 [==============================] - 1s 12ms/sample - loss: 0.0175 - val_loss: 0.0482\n",
      "Epoch 78/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0160 - val_loss: 0.0485\n",
      "Epoch 79/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0161 - val_loss: 0.0485\n",
      "Epoch 80/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0145 - val_loss: 0.0352\n",
      "Epoch 81/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.0128 - val_loss: 0.0386\n",
      "Epoch 82/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0124 - val_loss: 0.0477\n",
      "Epoch 83/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0106 - val_loss: 0.0420\n",
      "Epoch 84/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0102 - val_loss: 0.0377\n",
      "Epoch 85/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0090 - val_loss: 0.0402\n",
      "Epoch 86/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0090 - val_loss: 0.0390\n",
      "Epoch 87/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0081 - val_loss: 0.0352\n",
      "Epoch 88/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0079 - val_loss: 0.0347\n",
      "Epoch 89/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0072 - val_loss: 0.0368\n",
      "Epoch 90/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0069 - val_loss: 0.0372\n",
      "Epoch 91/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0067 - val_loss: 0.0332\n",
      "Epoch 92/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0064 - val_loss: 0.0337\n",
      "Epoch 93/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0060 - val_loss: 0.0339\n",
      "Epoch 94/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0061 - val_loss: 0.0328\n",
      "Epoch 95/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0059 - val_loss: 0.0334\n",
      "Epoch 96/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0053 - val_loss: 0.0341\n",
      "Epoch 97/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0055 - val_loss: 0.0313\n",
      "Epoch 98/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0050 - val_loss: 0.0288\n",
      "Epoch 99/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0049 - val_loss: 0.0296\n",
      "Epoch 100/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0045 - val_loss: 0.0306\n",
      "Epoch 101/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0044 - val_loss: 0.0299\n",
      "Epoch 102/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0042 - val_loss: 0.0302\n",
      "Epoch 103/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.0041 - val_loss: 0.0283\n",
      "Epoch 104/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0039 - val_loss: 0.0273\n",
      "Epoch 105/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.0038 - val_loss: 0.0284\n",
      "Epoch 106/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0037 - val_loss: 0.0281\n",
      "Epoch 107/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0036 - val_loss: 0.0274\n",
      "Epoch 108/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0035 - val_loss: 0.0273\n",
      "Epoch 109/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0034 - val_loss: 0.0272\n",
      "Epoch 110/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.0033 - val_loss: 0.0268\n",
      "Epoch 111/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0032 - val_loss: 0.0265\n",
      "Epoch 112/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0031 - val_loss: 0.0270\n",
      "Epoch 113/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0031 - val_loss: 0.0267\n",
      "Epoch 114/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0030 - val_loss: 0.0248\n",
      "Epoch 115/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0029 - val_loss: 0.0252\n",
      "Epoch 116/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0028 - val_loss: 0.0263\n",
      "Epoch 117/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.0028 - val_loss: 0.0257\n",
      "Epoch 118/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0027 - val_loss: 0.0253\n",
      "Epoch 119/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0026 - val_loss: 0.0247\n",
      "Epoch 120/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0026 - val_loss: 0.0246\n",
      "Epoch 121/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0025 - val_loss: 0.0243\n",
      "Epoch 122/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.0025 - val_loss: 0.0242\n",
      "Epoch 123/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.0024 - val_loss: 0.0244\n",
      "Epoch 124/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0024 - val_loss: 0.0238\n",
      "Epoch 125/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0023 - val_loss: 0.0233\n",
      "Epoch 126/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0023 - val_loss: 0.0232\n",
      "Epoch 127/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0022 - val_loss: 0.0230\n",
      "Epoch 128/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.0022 - val_loss: 0.0233\n",
      "Epoch 129/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0021 - val_loss: 0.0231\n",
      "Epoch 130/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0021 - val_loss: 0.0227\n",
      "Epoch 131/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0021 - val_loss: 0.0223\n",
      "Epoch 132/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0020 - val_loss: 0.0222\n",
      "Epoch 133/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0020 - val_loss: 0.0223\n",
      "Epoch 134/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0019 - val_loss: 0.0219\n",
      "Epoch 135/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0019 - val_loss: 0.0220\n",
      "Epoch 136/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0019 - val_loss: 0.0217\n",
      "Epoch 137/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.0018 - val_loss: 0.0216\n",
      "Epoch 138/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0018 - val_loss: 0.0214\n",
      "Epoch 139/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0018 - val_loss: 0.0212\n",
      "Epoch 140/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0018 - val_loss: 0.0213\n",
      "Epoch 141/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0017 - val_loss: 0.0211\n",
      "Epoch 142/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0017 - val_loss: 0.0210\n",
      "Epoch 143/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0017 - val_loss: 0.0207\n",
      "Epoch 144/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0016 - val_loss: 0.0209\n",
      "Epoch 145/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.0016 - val_loss: 0.0207\n",
      "Epoch 146/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0016 - val_loss: 0.0208\n",
      "Epoch 147/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0016 - val_loss: 0.0208\n",
      "Epoch 148/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.0015 - val_loss: 0.0204\n",
      "Epoch 149/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0015 - val_loss: 0.0200\n",
      "Epoch 150/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0015 - val_loss: 0.0204\n",
      "Epoch 151/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0015 - val_loss: 0.0203\n",
      "Epoch 152/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0014 - val_loss: 0.0201\n",
      "Epoch 153/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0014 - val_loss: 0.0199\n",
      "Epoch 154/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0014 - val_loss: 0.0197\n",
      "Epoch 155/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0014 - val_loss: 0.0199\n",
      "Epoch 156/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 0.0014 - val_loss: 0.0198\n",
      "Epoch 157/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0013 - val_loss: 0.0198\n",
      "Epoch 158/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0013 - val_loss: 0.0195\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.0013 - val_loss: 0.0194\n",
      "Epoch 160/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0013 - val_loss: 0.0192\n",
      "Epoch 161/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0013 - val_loss: 0.0191\n",
      "Epoch 162/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0012 - val_loss: 0.0191\n",
      "Epoch 163/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0012 - val_loss: 0.0189\n",
      "Epoch 164/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0012 - val_loss: 0.0190\n",
      "Epoch 165/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0012 - val_loss: 0.0191\n",
      "Epoch 166/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0012 - val_loss: 0.0188\n",
      "Epoch 167/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0012 - val_loss: 0.0189\n",
      "Epoch 168/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0011 - val_loss: 0.0189\n",
      "Epoch 169/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0011 - val_loss: 0.0190\n",
      "Epoch 170/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0011 - val_loss: 0.0188\n",
      "Epoch 171/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0011 - val_loss: 0.0184\n",
      "Epoch 172/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0011 - val_loss: 0.0184\n",
      "Epoch 173/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0011 - val_loss: 0.0187\n",
      "Epoch 174/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0011 - val_loss: 0.0186\n",
      "Epoch 175/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0010 - val_loss: 0.0186\n",
      "Epoch 176/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0010 - val_loss: 0.0184\n",
      "Epoch 177/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 0.0010 - val_loss: 0.0184\n",
      "Epoch 178/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 0.0010 - val_loss: 0.0183\n",
      "Epoch 179/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 9.9428e-04 - val_loss: 0.0181\n",
      "Epoch 180/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 9.8240e-04 - val_loss: 0.0181\n",
      "Epoch 181/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 9.7094e-04 - val_loss: 0.0182\n",
      "Epoch 182/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 9.5815e-04 - val_loss: 0.0180\n",
      "Epoch 183/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 9.4639e-04 - val_loss: 0.0180\n",
      "Epoch 184/200\n",
      "45/45 [==============================] - 1s 11ms/sample - loss: 9.3556e-04 - val_loss: 0.0180\n",
      "Epoch 185/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 9.2533e-04 - val_loss: 0.0182\n",
      "Epoch 186/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 9.1384e-04 - val_loss: 0.0180\n",
      "Epoch 187/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 9.0362e-04 - val_loss: 0.0181\n",
      "Epoch 188/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 8.9324e-04 - val_loss: 0.0179\n",
      "Epoch 189/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 8.8319e-04 - val_loss: 0.0179\n",
      "Epoch 190/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 8.7302e-04 - val_loss: 0.0180\n",
      "Epoch 191/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 8.6326e-04 - val_loss: 0.0179\n",
      "Epoch 192/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 8.5401e-04 - val_loss: 0.0177\n",
      "Epoch 193/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 8.4418e-04 - val_loss: 0.0176\n",
      "Epoch 194/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 8.3518e-04 - val_loss: 0.0178\n",
      "Epoch 195/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 8.2668e-04 - val_loss: 0.0178\n",
      "Epoch 196/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 8.1631e-04 - val_loss: 0.0178\n",
      "Epoch 197/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 8.0792e-04 - val_loss: 0.0175\n",
      "Epoch 198/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 7.9866e-04 - val_loss: 0.0176\n",
      "Epoch 199/200\n",
      "45/45 [==============================] - 0s 10ms/sample - loss: 7.9018e-04 - val_loss: 0.0175\n",
      "Epoch 200/200\n",
      "45/45 [==============================] - 0s 11ms/sample - loss: 7.8125e-04 - val_loss: 0.0175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb3919e4a8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input_data, decoder_input_data],\n",
    "          y=decoder_output_data,\n",
    "          batch_size=8, epochs=200,\n",
    "          validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3. 최적의 출력 순차 데이터 구하기\n",
    "---\n",
    "\n",
    "* Decoding을 할 때 우리는 가장 높은 확률의 조합으로 이루어진 출력 순차 데이터를 구해야 합니다.<br>\n",
    "* 그렇게 하기 위해서는 모든 출력의 조합을 확률로 계산을 해보아야 하는데, 그것은 연산량이 지나치게 많아 사실상 불가능에 가깝습니다.<br>\n",
    "* 근사적인 답을 찾는 2가지 방법에 대해 배워보도록 하겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### (1) 가장 높은 확률의 단어만 선택하기, greedy Search\n",
    "\n",
    "기본적으로는 각 단계에서 가장 높은 확률의 조합만으로 가는 것을 Greedy Search라 부릅니다. 직관적으로 보통 가장 높은 확률의 단어만으로 갔을 때, 최적의 답이 나올 것이라 기대하는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love you\n"
     ]
    }
   ],
   "source": [
    "test_sequence = \"나는 너를 사랑해\"\n",
    "\n",
    "# 영어 문장을 code로 embedding하기 \n",
    "test_inputs = np.array([kor2idx[char] for char in test_sequence])\n",
    "test_inputs = test_inputs[np.newaxis]\n",
    "\n",
    "# Encoder 모델을 통해 Context 벡터 계산하기\n",
    "context_h, context_c = encoder_model.predict(test_inputs)\n",
    "contexts = [context_h, context_c] # context 벡터\n",
    "\n",
    "# Decoder 모델 첫 단어 구성하기\n",
    "start_word = \"\\n\"\n",
    "pred_inputs = np.array([[eng2idx[start_word]]])\n",
    "\n",
    "# Decoder을 통해 출력값 가져오기\n",
    "pred_outputs = decoder_model.predict([pred_inputs]+contexts)\n",
    "probs = pred_outputs[0]\n",
    "states = pred_outputs[1:]\n",
    "\n",
    "# 출력값중 가장 높은 확률값의 인덱스 가져오기\n",
    "top_index = probs.argmax(axis=-1)\n",
    "last_word = eng_chars[top_index.squeeze()]\n",
    "\n",
    "# 위의 과정을 반복\n",
    "pred_sequence = \"\"\n",
    "while last_word != \"\\t\" and last_word != \"\\n\":\n",
    "    # <EOS> 토큰이 나오거나, 멈추지 않는 현상을 방지\n",
    "    pred_sequence += last_word\n",
    "    \n",
    "    pred_outputs = decoder_model.predict([top_index]+states)\n",
    "    probs = pred_outputs[0]\n",
    "    states = pred_outputs[1:]\n",
    "    \n",
    "    top_index = probs.argmax(axis=-1)\n",
    "    last_word = eng_chars[top_index[0][0]]\n",
    "\n",
    "print(pred_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만, 꼭 가장 높은 확률의 단어로만 갔을 때, 정답을 보장하지 않습니다. 이전 출력의 기록에 따라 다음 출력의 결과물들이 바뀌기 때문입니다. 특히 영어 문장에서는 첫 단어로 i가 나올 가능성이 높기 때문에, 어떤 입력 문장이든 첫 단어로 i를 반환할 가능성이 매우 높습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 몇 개의 후보군을 비교해가며 진행하기, Beam Search\n",
    "\n",
    "Greedy Search는 원치 않은 잘못된 결과를 반환할 수 있습니다. 이를 방지하기 위해, 우리는 Beam Search라고 불리는 방법은 각 단계에서 단어를 N개 예측 후 조합하는데, 이 때 가장 확률이 높은 후보 군(Beam size)만큼을 남기고 다음 스텝을 진행하는 방식입니다. <br>\n",
    "Beam Search는 일종의 Dynamic Programming입니다. 코드 난이도가 있으니 잘 살펴 보시길 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('i believe you\\n', 0.008965726932988869), ('i relieve you\\n', 0.25235972004364676), ('i hate you\\n', 0.2569068585911406), ('i bespect you\\n', 0.45489259238508695), ('i hete you\\n', 0.5279026596412719)]\n"
     ]
    }
   ],
   "source": [
    "test_sequence = \"나는 널 믿어\"\n",
    "\n",
    "k = 5 # Beam Search의 크기\n",
    "\n",
    "completed_k = 0 # 완료된 서치\n",
    "completed_sequences = [] # 완료된 시퀀스\n",
    "completed_scores = [] # 완료된 시퀀스의 점수\n",
    "\n",
    "live_k = k\n",
    "live_sequences = np.array([[]]) # 탐색 중인 시퀀스\n",
    "live_scores = np.array([0]) # 탐색 중인 점수\n",
    "\n",
    "# 문장을 kor2idx로 인코딩하기\n",
    "test_inputs = np.array([kor2idx[char] for char in test_sequence])\n",
    "test_inputs = test_inputs[np.newaxis]\n",
    "\n",
    "# Encoder 모델을 통해 Context 벡터 계산하기\n",
    "context_h, context_c = encoder_model.predict(test_inputs)\n",
    "\n",
    "# Decoder 모델 첫 단어 구성하기\n",
    "start_word = \"\\n\"\n",
    "start_inputs = np.array([eng2idx[start_word]])\n",
    "\n",
    "# Decoder 모델의 초기 상태 값 구성하기\n",
    "contexts = [context_h, context_c] # context 벡터\n",
    "# 그외 2개의 상태 벡터의 초깃값\n",
    "other_state =[np.zeros_like(context_h) for _ in range(2)] \n",
    "\n",
    "initial_state = contexts + other_state \n",
    "\n",
    "# Decoder을 통해 출력값 가져오기\n",
    "pred_outputs = decoder_model.predict([start_inputs]+initial_state)\n",
    "probs = pred_outputs[0]\n",
    "states = pred_outputs[1:]\n",
    "\n",
    "while True:\n",
    "    # 후보군들의 점수 계산하기\n",
    "    candidate_scores = live_scores[:,None,None]-np.log(probs) # 점수 계산, 음수로 하였기 때문에 작을수록 좋은 값\n",
    "    # (batch size, time steps, char size) -> (batch size, char size)\n",
    "    candidate_scores = candidate_scores[:,0,:] # 단어 별로 진행하기 때문에, time steps =1 \n",
    "    \n",
    "    # 상위 (k-completed_k)개의 점수 \n",
    "    live_scores = np.sort(candidate_scores.ravel())[:(k-completed_k)]\n",
    "    \n",
    "    # 상위 (k-completed_k)개의 (batch index, char index) 가져오기\n",
    "    # reference : have numpy argsort return an array of 2d indices?\n",
    "    # https://stackoverflow.com/questions/30577375/have-numpy-argsort-return-an-array-of-2d-indices\n",
    "    rank_indices = np.dstack(\n",
    "        np.unravel_index(\n",
    "            np.argsort(candidate_scores.ravel()),\n",
    "            candidate_scores.shape))[0,:(k-completed_k)]\n",
    "\n",
    "    # batch index와 char index를 가져오기\n",
    "    batch_indices = rank_indices[:,0] # 각 배치 별로 next state 값이 다름\n",
    "    char_indices = rank_indices[:,1]  # 각 char 별로 next input 값이 다름 \n",
    "    \n",
    "    # 이전 시퀀스를 rank 순서에 맞게 가져오기\n",
    "    prev_sequences = np.array(live_sequences)[batch_indices] # 각 배치는 이전 시퀀스를 의미\n",
    "    next_words = np.array([eng_chars[idx] for idx in char_indices])[:,None] # 다음 분기에 해당하는 word 가져오기\n",
    "    live_sequences = np.concatenate((prev_sequences, next_words),axis=1)\n",
    "    \n",
    "    del_list = []\n",
    "    for idx, word in enumerate(next_words):\n",
    "        if word == EOS:\n",
    "            # EOS를 만나면, 그 행은 완결된 Sequence\n",
    "            completed_k += 1            \n",
    "            completed_seq = \"\".join(live_sequences[idx]) # [\"i\",\" \",\"h\",\"a\",\"t\",\"e\",...] -> \"i hate ...\"\n",
    "            completed_sequences.append(completed_seq) \n",
    "            # 길이가 길수록 계속 더해지기 때문에 점수가 커집니다. 장문이 기본적으로 단문보다 score가 크게 잡히기 때문에\n",
    "            # 이를 보정하기 위해, 나누어 주어야 합니다.\n",
    "            completed_scores.append(live_scores[idx] /len(completed_seq))\n",
    "            del_list.append(idx)\n",
    "            \n",
    "    # 탐색 중인 시퀀스에서 제거하기, 탐색할 수는 len(del_list)만큼 줄어듦\n",
    "    live_sequences = np.delete(live_sequences, del_list, axis=0)\n",
    "    live_scores = np.delete(live_scores, del_list, axis=0)\n",
    "    batch_indices = np.delete(batch_indices, del_list, axis=0)\n",
    "    char_indices = np.delete(char_indices, del_list, axis=0)\n",
    "    \n",
    "    # 탐색 종료 조건\n",
    "    if completed_k >= k:\n",
    "        # 모든 시퀀스를 다 찾은 경우 종료\n",
    "        break\n",
    "    \n",
    "    # 다음 Sequence에 들어갈 input 값과 상태 값 가져오기\n",
    "    next_inputs = char_indices[:,None] # (num indices,) -> (num indices, 1)\n",
    "    next_states = [state[batch_indices] for state in states]\n",
    "\n",
    "    # 모델에 inference하기\n",
    "    pred_outputs = decoder_model.predict([next_inputs]+next_states)\n",
    "    probs = pred_outputs[0]\n",
    "    states = pred_outputs[1:]\n",
    "\n",
    "# Score에 따라 정렬하기\n",
    "result = list(zip(completed_sequences, completed_scores))\n",
    "result = sorted(result, key=lambda x: x[1]) # Score는 낮을수록 좋은 값\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 Score는 작을수록 더 정확하게 예측했다는 것을 의미합니다. \"나는 너를 믿어\"를 보고, 가장 유사한 번역 후보군 5개로 위의 것들을 추론했고, 그 중 i believe you가 가장 높은 값을 보였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "1. [Seq2Seq Paper](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)\n",
    "2. [Visualizing A Neural Machine Translation Model ](http://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)\n",
    "3. [Keras를 이용해 Seq2Seq을 10분안에 알려주기](https://tykimos.github.io/2018/09/14/ten-minute_introduction_to_sequence-to-sequence_learning_in_Keras/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
